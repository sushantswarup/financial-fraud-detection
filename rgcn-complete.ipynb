{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c ieee-fraud-detection -p ./data/ieee-fraud-detection/ --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./data/ieee-fraud-detection/ieee-fraud-detection.zip -d ./data/ieee-fraud-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity = pd.read_csv('./data/ieee-fraud-detection/train_identity.csv')\n",
    "df_transaction = pd.read_csv('./data/ieee-fraud-detection/train_transaction.csv')\n",
    "\n",
    "df=pd.merge(df_identity, df_transaction, on='TransactionID', how='inner')\n",
    "\n",
    "df.sort_values(by='TransactionDT', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(df)\n",
    "n_train = int(n_total*0.8)\n",
    "n_test  = n_total - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total transactions: {n_total}, training transactions: {n_train}, testing transaction: {n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(n_train)\n",
    "df_test  = df.tail(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"./data/train.parquet\", index=False)\n",
    "df_test.to_parquet(\"./data/test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushant_p18/anaconda3/envs/Lab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Volumes/Passport/Projects/Financial-Fraud-Detection/rgcn-fraud-detector/fgnn/fraud_detector.py:34: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.options.mode.use_inf_as_na = True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "from fgnn.fraud_detector import FraudRGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('./data/train.parquet')\n",
    "df_test = pd.read_parquet('./data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding_size': 64,\n",
    "    'n_layers': 2,\n",
    "    'n_epochs': 2,\n",
    "    'n_hidden': 16,\n",
    "    'dropout': 0.2,\n",
    "    'weight_decay': 5e-05,\n",
    "    'lr': 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_gpus': 0,\n",
       " 'embedding_size': 128,\n",
       " 'n_layers': 2,\n",
       " 'n_epochs': 50,\n",
       " 'n_hidden': 16,\n",
       " 'dropout': 0.2,\n",
       " 'weight_decay': 5e-06,\n",
       " 'lr': 0.01,\n",
       " 'target_col': 'TransactionID',\n",
       " 'node_cols': 'card1,card2,card3,card4,card5,card6,ProductCD,addr1,addr2,P_emaildomain,R_emaildomain',\n",
       " 'label_col': 'isFraud',\n",
       " 'cat_cols': 'M1,M2,M3,M4,M5,M6,M7,M8,M9,DeviceType,DeviceInfo,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38',\n",
       " 'num_cols': 'TransactionAmt,dist1,dist2,id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_11,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V23,V24,V25,V26,V27,V28,V29,V30,V31,V32,V33,V34,V35,V36,V37,V38,V39,V40,V41,V42,V43,V44,V45,V46,V47,V48,V49,V50,V51,V52,V53,V54,V55,V56,V57,V58,V59,V60,V61,V62,V63,V64,V65,V66,V67,V68,V69,V70,V71,V72,V73,V74,V75,V76,V77,V78,V79,V80,V81,V82,V83,V84,V85,V86,V87,V88,V89,V90,V91,V92,V93,V94,V95,V96,V97,V98,V99,V100,V101,V102,V103,V104,V105,V106,V107,V108,V109,V110,V111,V112,V113,V114,V115,V116,V117,V118,V119,V120,V121,V122,V123,V124,V125,V126,V127,V128,V129,V130,V131,V132,V133,V134,V135,V136,V137,V138,V139,V140,V141,V142,V143,V144,V145,V146,V147,V148,V149,V150,V151,V152,V153,V154,V155,V156,V157,V158,V159,V160,V161,V162,V163,V164,V165,V166,V167,V168,V169,V170,V171,V172,V173,V174,V175,V176,V177,V178,V179,V180,V181,V182,V183,V184,V185,V186,V187,V188,V189,V190,V191,V192,V193,V194,V195,V196,V197,V198,V199,V200,V201,V202,V203,V204,V205,V206,V207,V208,V209,V210,V211,V212,V213,V214,V215,V216,V217,V218,V219,V220,V221,V222,V223,V224,V225,V226,V227,V228,V229,V230,V231,V232,V233,V234,V235,V236,V237,V238,V239,V240,V241,V242,V243,V244,V245,V246,V247,V248,V249,V250,V251,V252,V253,V254,V255,V256,V257,V258,V259,V260,V261,V262,V263,V264,V265,V266,V267,V268,V269,V270,V271,V272,V273,V274,V275,V276,V277,V278,V279,V280,V281,V282,V283,V284,V285,V286,V287,V288,V289,V290,V291,V292,V293,V294,V295,V296,V297,V298,V299,V300,V301,V302,V303,V304,V305,V306,V307,V308,V309,V310,V311,V312,V313,V314,V315,V316,V317,V318,V319,V320,V321,V322,V323,V324,V325,V326,V327,V328,V329,V330,V331,V332,V333,V334,V335,V336,V337,V338,V339',\n",
       " 'class_weight': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print default model parameters\n",
    "FraudRGCN()._default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model in inductive setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "### disable CUDA-related warnings from torch library \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushant_p18/anaconda3/envs/Lab/lib/python3.10/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log10\n",
      "  result = func(self.values, **kwargs)\n",
      "/Users/sushant_p18/anaconda3/envs/Lab/lib/python3.10/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed heterograph with the following metagraph structure: Node types ['P_emaildomain', 'ProductCD', 'R_emaildomain', 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'target'], Edge types[('P_emaildomain', 'P_emaildomain<>target', 'target'), ('ProductCD', 'ProductCD<>target', 'target'), ('R_emaildomain', 'R_emaildomain<>target', 'target'), ('addr1', 'addr1<>target', 'target'), ('addr2', 'addr2<>target', 'target'), ('card1', 'card1<>target', 'target'), ('card2', 'card2<>target', 'target'), ('card3', 'card3<>target', 'target'), ('card4', 'card4<>target', 'target'), ('card5', 'card5<>target', 'target'), ('card6', 'card6<>target', 'target'), ('target', 'self_relation', 'target'), ('target', 'target<>P_emaildomain', 'P_emaildomain'), ('target', 'target<>ProductCD', 'ProductCD'), ('target', 'target<>R_emaildomain', 'R_emaildomain'), ('target', 'target<>addr1', 'addr1'), ('target', 'target<>addr2', 'addr2'), ('target', 'target<>card1', 'card1'), ('target', 'target<>card2', 'card2'), ('target', 'target<>card3', 'card3'), ('target', 'target<>card4', 'card4'), ('target', 'target<>card5', 'card5'), ('target', 'target<>card6', 'card6')]\n",
      "Number of nodes of type target : 115386\n"
     ]
    }
   ],
   "source": [
    "for ii in range(1,6):\n",
    "    fd = FraudRGCN()\n",
    "    fd.train_fg(df_train, params=params)\n",
    "    fd.save_fg(f\"model/inductive_{ii}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from fgnn.fraud_detector import FraudRGCN\n",
    "\n",
    "import torch as th\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate trained models on full test set and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "## evaluate models on full test set\n",
    "# for mode in ['transductive', 'inductive' ]:\n",
    "for mode in ['inductive' ]:\n",
    "    for ii in range(1,6):\n",
    "        for kk in [1, 2, 3]:\n",
    "            fd = FraudRGCN.load_fg(f\"model/{mode}_{ii}\")\n",
    "            fraud_proba=fd.predict(df_test, k=kk)\n",
    "            auc=roc_auc_score(df_test.isFraud, fraud_proba)\n",
    "            elaps=fd._timings['predict: total'][-1]\n",
    "            print(mode, ii, kk, elaps, auc)\n",
    "            results.append((mode, ii, kk, elaps, auc))\n",
    "            \n",
    "## save results to csv\n",
    "df_results = pd.DataFrame(results, columns=['mode', 'trial', 'k', 'time', 'AUC'])\n",
    "df_results.to_csv('full_results.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate inductive models on test set in batches and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = []\n",
    "\n",
    "## evaluate inductive models on test set in batches of ~1000 transactions\n",
    "for mode in ['inductive',]:\n",
    "    for ii in range(1,6):\n",
    "        for kk in [1, 2, 3,]:\n",
    "            fd = FraudRGCN.load_fg(f\"model/{mode}_{ii}\")\n",
    "            fraud_proba=[]\n",
    "            for batch in np.array_split(df_test, 28):\n",
    "                fraud_proba.append(fd.predict(batch, k=kk))\n",
    "                \n",
    "                n_nodes = th.sum(th.tensor([fd._train_g.number_of_nodes(n_type) for n_type in fd._train_g.ntypes]))\n",
    "                n_lookup = np.sum([len(lookup) for ntype, lookup in fd._nodes_lookup.items()])\n",
    "                \n",
    "                n_edges = th.sum(th.tensor([fd._train_g.number_of_edges(e_type) for e_type in fd._train_g.etypes]))\n",
    "\n",
    "                print(\"\"\"----After Inference Internal Storage------'\n",
    "                            #Nodes: {}\n",
    "                            #Edges: {}\n",
    "                            #Lookup keys: {}\n",
    "                            \"\"\".format(n_nodes,n_edges, n_lookup))\n",
    "\n",
    "            fraud_proba=np.concatenate(fraud_proba)\n",
    "            \n",
    "            auc=roc_auc_score(df_test.isFraud, fraud_proba)\n",
    "            elaps=np.mean(fd._timings['predict: total'])\n",
    "            \n",
    "            print(mode, ii, kk, elaps, auc)\n",
    "            batch_results.append((mode, ii, kk, elaps, auc))\n",
    "            \n",
    "## save results to csv\n",
    "df_batch_results = pd.DataFrame(batch_results, columns=['mode', 'trial', 'k', 'time', 'AUC'])\n",
    "df_batch_results.to_csv('batch_results.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.groupby(by=['mode', 'k'], as_index=False).mean().drop(columns=['trial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch_results.groupby(by=['mode', 'k'], as_index=False).mean().drop(columns=['trial'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
